{"cells":[{"cell_type":"code","source":["train_datapath='/FileStore/tables/train.csv'\ntest_datapath='/FileStore/tables/test.csv'\ntraindata_rdd = sc.textFile(train_datapath)\ntestdata_rdd = sc.textFile(test_datapath)"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["traindata_rdd.take(3)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["testdata_rdd.take(3)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["def parseTrain(rdd):\n  \n  \n \n\n  header = rdd.first()\n   \n  body = rdd.filter(lambda r: r!=header)\n  def parseRow(row):\n    \n       \n    row_list = row.replace('\"','').split(\",\")\n       \n    row_tuple = tuple(row_list)\n    return row_tuple\n  \n  \n \n  rdd_parsed = body.map(parseRow)\n \n  colnames = header.split(\",\")\n  colnames.insert(3,'FirstName')\n \n  return rdd_parsed.toDF(colnames)\n\n \ndef parseTest(rdd):\n  \n  header = rdd.first()\n  body = rdd.filter(lambda r: r!=header)\n \n  def parseRow(row):\n    row_list = row.replace('\"','').split(\",\")\n    row_tuple = tuple(row_list)\n    return row_tuple\n  rdd_parsed = body.map(parseRow)\n  colnames = header.split(\",\")\n  colnames.insert(2,'FirstName')\n  return rdd_parsed.toDF(colnames)\n \ntraindata_df = parseTrain(traindata_rdd)\ntestdata_df = parseTest(testdata_rdd)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["traindata_df.show(3)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["from pyspark.sql.functions import lit, col\ntraindata_df = traindata_df.withColumn('Mark',lit('train'))\ntestdata_df = (testdata_df.withColumn('Survived',lit(0))\n                  .withColumn('Mark',lit('test')))\ntestdata_df = testdata_df[traindata_df.columns]\n## Append Test data to Train data\ndf = traindata_df.unionAll(testdata_df)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["df.show(20)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["df.show(2)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["from pyspark.sql.functions import udf\nfrom pyspark.sql.types import StringType\n \n## created user defined function to extract title\ngetTitlename = udf(lambda name: name.split('.')[0].strip(),StringType())\ndf = df.withColumn('Title', getTitlename(df['Name']))\n \ndf.select('Name','Title').show(3)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["df.show(2)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["df = (df.withColumn('Age',df['Age'].cast('double'))\n            .withColumn('SibSp',df['SibSp'].cast('double'))\n            .withColumn('Parch',df['Parch'].cast('double'))\n            .withColumn('Fare',df['Fare'].cast('double'))\n            .withColumn('Survived',df['Survived'].cast('double'))\n            )\ndf.printSchema()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["numVars = ['Survived','Age','SibSp','Parch','Fare']\ndef countNullvalues(df,var):\n    return df.where(df[var].isNull()).count()\n \nmissing_Variables = {var: countNullvalues(df,var) for var in numVars}\nage_mean = df.groupBy().mean('Age').first()[0]\nfare_mean = df.groupBy().mean('Fare').first()[0]\ndf = df.na.fill({'Age':age_mean,'Fare':fare_mean})\ndf.show(5)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n\ncategoricalColumnsnames = [\"Sex\"]\nstages = [] # stages in our Pipeline\nfor categoricalColdata in categoricalColumnsnames:\n  # Category Indexing with StringIndexer\n  stringIndexer = StringIndexer(inputCol=categoricalColdata, outputCol=categoricalCol+\"Index\")\n  # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n  encoder = OneHotEncoder(inputCol=categoricalColdata+\"Index\", outputCol=categoricalCol+\"classVec\")\n  # Add stages.  These are not run here, but will run all at once later on.\n  stages += [stringIndexer, encoder]"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["label_stringIdxname = StringIndexer(inputCol = \"Survived\", outputCol = \"label\")\nstages += [label_stringIdxname]"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["numericColsname = [ \"Age\", \"SibSp\", \"Parch\",\"Fare\"]\nassemblerInputs = map(lambda c: c + \"classVec\", categoricalColumnsnames) + numericColsname\nassembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\nstages += [assembler]"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["df.show()"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["colname = df.columns\n# Create a Pipeline.\npipeline = Pipeline(stages=stages)\n# Run the feature transformations.\n#  - fit() computes feature statistics as needed.\n#  - transform() actually transforms the features.\npipelineModel = pipeline.fit(df)\ndataset = pipelineModel.transform(df)\n\n# Keep relevant columns\nselectedcols = [\"label\", \"features\"] + colname\ndataset = dataset.select(selectedcols)\n#display(dataset)\n#type(dataset)\ndataset.toPandas()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["df.show(2)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["train_df = dataset.where(df.Mark =='train')\ntest_df = dataset.where(df.Mark =='test')"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["(trainingsetdata, Validatesetdata) = train_df.randomSplit([0.70, 0.30], seed = 121)\nprint trainingsetdata.count()\nprint Validatesetdata.count()"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n# Create initial LogisticRegression model\nlr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\")\n\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n# Create ParamGrid for Cross Validation\nparamGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, [0.01, 0.5, 2.0])\n             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n             .addGrid(lr.maxIter, [1, 5, 10,15])\n             .build())\n\n# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations\ncvModel = cv.fit(train_df)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["predict = cvModel.transform(Validatesetdata)\npredictions.printSchema()"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["actual_datalist = predictions.select('Survived').collect()\nprediction_datalist = predictions.select('prediction').collect()\nactual_dataarray = [float(i.Survived) for i in actual_datalist]\npredict_dataarray = [float(i.prediction) for i in prediction_datalist]\n\ndef accuracy_calculation(list1, list2):\n  length = len(list1)\n  accum = 0 \n  for i in range (length):\n    if list1[i] == list2[i]:\n      accum += 1\n      accuracy = float(accum)/float(length)\n  return accuracy \naccuracy_calculation(actual_datalist,prediction_datalist)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["print 'Model Intercept: ', cvModel.bestModel.intercept"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["weights = cvModel.bestModel.coefficients\nweights = map(lambda w: (float(w),), weights)  # convert numpy type to float, and to tuple\nweightsDF = sqlContext.createDataFrame(weights, [\"Feature Weight\"])\nweightsDF.toPandas()"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["from pyspark.ml.classification import DecisionTreeClassifier\n\n# Create initial Decision Tree Model\ndt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n(trainingDataset, ValidateDataset) = train_df.randomSplit([0.70, 0.30], seed = 121)\nprint trainingDataset.count()\nprint ValidateDataset.count()"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(dt.maxDepth, [1,2,6,10])\n             .addGrid(dt.maxBins, [20,40,80])\n             .build())\ncv = CrossValidator(estimator=dt, estimatorParamMaps=paramGrid, evaluator=evaluator)\ncvModel = cv.fit(train_df)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["print \"numNodes = \", cvModel.bestModel.numNodes\nprint \"depth = \", cvModel.bestModel.depth\npredictions_Dtree = cvModel.transform(ValidateDataset)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["actual_datalist = predictions_Dtree.select('Survived').collect()\nprediction_datalist = predictions_Dtree.select('prediction').collect()\nactual_dataarray = [float(i.Survived) for i in actual_datalist]\npredict_dataarray = [float(i.prediction) for i in prediction_datalist]\n\n\naccuracy_cal(actual_datalist,prediction_datalist)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["from pyspark.ml.classification import RandomForestClassifier\n\n# Create an initial RandomForest model.\nrf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n(trainingDataset, ValidateDataset) = train_df.randomSplit([0.70, 0.30])"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(rf.maxDepth, [2, 4, 6])\n             .addGrid(rf.maxBins, [20, 60])\n             .addGrid(rf.numTrees, [5, 20])\n             .build())\ncv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator)\n\n# Run cross validations.  This can take about 6 minutes since it is training over 20 trees!\ncvModel = cv.fit(trainingDataset)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["predictions_RF = cvModel.transform(ValidateDataset)"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["evaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["actual_datalist = predictions_RF.select('Survived').collect()\nprediction_datalist = predictions_RF.select('prediction').collect()\nactual_dataarray = [float(i.Survived) for i in actual_datalist]\npredict_dataarray = [float(i.prediction) for i in prediction_datalist]\n\n\naccuracy_cal(actual_datalist,prediction_datalist)"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["from pyspark.ml.classification import MultilayerPerceptronClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["(trainingDataset, ValidateDataset) = train_df.randomSplit([0.70, 0.30], seed = 122)\nlayers = [24, 5, 4, 2]\nmp = MultilayerPerceptronClassifier(layers = layers)"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(mp.maxIter, [50,100,200])\n             .addGrid(mp.blockSize, [128,256,512])\n             .addGrid(mp.seed, [1234,3223])\n             .build())\nevaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n\ncv = CrossValidator(estimator=mp, estimatorParamMaps=paramGrid, evaluator=evaluator)\n\n\n# Run cross validations.  \ncvModel = cv.fit(trainingDataset)"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["predictions_mc = cvModel.transform(ValidateData)"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["evaluator.evaluate(predictions_mc)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["bestModelcalculation = cvModel.bestModel\n# Generate predictions for entire dataset\nfinalPredictions = bestModelcalculation.transform(ValidateData)\nfinalPredictions.printSchema()\n# Evaluate best model\nevaluator.evaluate(finalPredictions)"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":46}],"metadata":{"name":"Spark_Assignment2","notebookId":2107539003741753},"nbformat":4,"nbformat_minor":0}
